{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e78fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series  # for convenience\n",
    "\n",
    "\n",
    "import pims\n",
    "import trackpy as tp\n",
    "import av\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def find_complete_intervals(df, p_num):\n",
    "    p_frames = df.loc[df['particle']==p_num, 'frame']\n",
    "    p_intervals = [] # array of tuples containing start and end for each continous interval where particle is detected\n",
    "    start = True\n",
    "    first_start = True\n",
    "    prev, curr = 0, 0\n",
    "    for i in p_frames: # this actually serves as an index, i.e if p0 is not detected during frame 14, then there is no element 14, only an element 13 then 15\n",
    "        if first_start: prev = i; first_start = False\n",
    "        curr = i\n",
    "        if curr-prev > 1:\n",
    "            # frame jumping\n",
    "            #print(\"frame skip: \",prev, curr)\n",
    "            start = True\n",
    "\n",
    "        if start:\n",
    "            if len(p_intervals) != 0: p_intervals[-1][1] = prev\n",
    "            p_intervals.append([curr, -69]) # error will occur if -69 not overwritten\n",
    "        start = False\n",
    "        prev = curr\n",
    "    #print(p_intervals)\n",
    "    if len(p_intervals) != 0: p_intervals[-1][1] = curr\n",
    "    #else: print(\"Intervals too short\", p_intervals)\n",
    "    #print(p_intervals)\n",
    "    return p_intervals\n",
    "\n",
    "#tv.loc[(tv['particle']==0) & (tv['frame']==3), ['speed']] = 0.9 # assigning a specific frame  \n",
    "\n",
    "def dist(y1, x1, y2, x2): # compute 2D euclidean norm:\n",
    "    return np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "\n",
    "def compute_speeds(df, p_num, p_intervals) : # compute speeds of single particle over a complete interval\n",
    "    short_count = 0\n",
    "    p = df.loc[df['particle']==p_num]\n",
    "    for i_start, i_end in p_intervals:\n",
    "        if i_end-i_start == 0: \n",
    "            #print(f\"Interval length too short: {i_end-i_start=}\")\n",
    "            df.loc[(df['particle']==p_num) & (tv['frame']==i_start), 'speed'] == None\n",
    "            df.loc[(df['particle']==p_num) & (tv['frame']==i_start), 'vx'] == None\n",
    "            df.loc[(df['particle']==p_num) & (tv['frame']==i_start), 'vy'] == None\n",
    "            short_count += 1\n",
    "            continue\n",
    "        for i in range(i_start, i_end+1): # i is a frame_index\n",
    "            if i == i_start: # start of the interval, differentiate over single time_step\n",
    "                df.loc[(df['particle']==p_num) & (tv['frame']==i), 'speed'] = dist(p['y'][i], p['x'][i], p['y'][i+1], p['x'][i+1]) # px/frame\n",
    "                df.loc[(df['particle']==p_num) & (tv['frame']==i), 'vx'] =  p.loc[i+1, 'x'] - p.loc[i, 'x'] # px/frame \n",
    "                df.loc[(df['particle']==p_num) & (tv['frame']==i), 'vy'] =  p.loc[i+1, 'y'] - p.loc[i, 'y'] # px/frame \n",
    "                #print(p0)\n",
    "            elif i == i_end: # end of interval\n",
    "                df.loc[(df['particle']==p_num) & (tv['frame']==i), 'speed'] = dist(p['y'][i-1], p['x'][i-1], p['y'][i], p['x'][i])\n",
    "                df.loc[(df['particle']==p_num) & (tv['frame']==i), 'vx'] =  p.loc[i, 'x'] - p.loc[i-1, 'x'] # px/frame \n",
    "                df.loc[(df['particle']==p_num) & (tv['frame']==i), 'vy'] =  p.loc[i, 'y'] - p.loc[i-1, 'y'] # px/frame \n",
    "            else: # neither start nor beginner, we can average speed over 2 frames for more numerical stability\n",
    "                df.loc[(df['particle']==p_num) & (tv['frame']==i), 'speed'] = dist(p['y'][i-1], p['x'][i-1], p['y'][i+1], p['x'][i+1])/2\n",
    "                df.loc[(df['particle']==p_num) & (tv['frame']==i), 'vx'] =  (p.loc[i+1, 'x'] - p.loc[i-1, 'x'])/2 # px/frame \n",
    "                df.loc[(df['particle']==p_num) & (tv['frame']==i), 'vy'] = (p.loc[i+1, 'y'] - p.loc[i-1, 'y'])/2 # px/frame \n",
    "    return df, short_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd897c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video filepaths\n",
    "\n",
    "filepaths = [\n",
    "    \"videos/1.75g_cropped/1.75g@15Hz.mov\",\n",
    "    \"videos/1.75g_cropped/1.75g@18Hz.mov\",\n",
    "    \"videos/1.75g_cropped/1.75g@20Hz.mov\",\n",
    "    \"videos/1.75g_cropped/1.75g@22Hz.mov\",\n",
    "    \"videos/1.75g_cropped/1.75g@24Hz.mov\",\n",
    "    \"videos/1.75g_cropped/1.75g@26Hz.mov\",\n",
    "    \"videos/1.75g_cropped/1.75g@28Hz.mov\",\n",
    "    \"videos/1.75g_cropped/1.75g@30Hz.mov\",\n",
    "    \"videos/1.75g_cropped/1.75g@32Hz.mov\",\n",
    "    \"videos/1.75g_cropped/1.75g@34Hz.mov\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a1f434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on file videos/1.75g_cropped/1.75g@18Hz.mov\n",
      "breakpoint 1\n"
     ]
    }
   ],
   "source": [
    "tp.quiet()  # Turn off progress reports for best performance\n",
    "\n",
    "fp = filepaths[1]\n",
    "\n",
    "\n",
    "PARAMS = {\n",
    "\"diameter\": 13,\n",
    "\"threshold\": 0,\n",
    "\"minmass\": 1000\n",
    "}\n",
    "\n",
    "print(f\"Working on file {fp}\")\n",
    "\n",
    "frames = pims.as_grey(pims.PyAVReaderTimed(fp))\n",
    "\n",
    "print(\"breakpoint 1\")\n",
    "f = tp.batch(frames, diameter=PARAMS['diameter'], threshold=PARAMS['threshold'], minmass=PARAMS['minmass'])\n",
    "print(\"breakpoint 2\")\n",
    "t = tp.link(f, 5, memory=3) # this tracks the location of each particle by establishing continuity from frame to frame\n",
    "\n",
    "t1 = tp.filter_stubs(t, 10)\n",
    "\n",
    "t2 = t1 # don't do any additional filtering, we can do this afterwards once we have csv - avoid throwing away potentially good data\n",
    "\n",
    "# skip the MSD step, we can do that from PSD\n",
    "\n",
    "# compute particle velocities\n",
    "tv = t2.copy()\n",
    "tv.insert(len(tv.columns), 'speed', 0.)\n",
    "tv.insert(len(tv.columns), 'vx', 0.)\n",
    "tv.insert(len(tv.columns), 'vy', 0.)\n",
    "particle_num = np.max(tv['particle'])\n",
    "\n",
    "short_count = 0\n",
    "for i in range(particle_num+1):\n",
    "    p = tv[tv['particle']==i]\n",
    "    p_intervals = find_complete_intervals(tv, p_num=i)\n",
    "    #print(p_intervals)\n",
    "    tv, sc = compute_speeds(tv, i, p_intervals)\n",
    "    short_count += sc\n",
    "\n",
    "print(f\"Number of short intervals without well defined velocity {short_count}\")\n",
    "print(f\"Particle number: {particle_num}\")\n",
    "\n",
    "save_dir = \"data/1.75g\"\n",
    "save_name = os.path.splitext(os.path.basename(fp))[0]\n",
    "save_path = os.path.join(save_dir, save_name+\".csv\")\n",
    "print(save_path)\n",
    "tv.to_csv(save_path)\n",
    "\n",
    "\n",
    "\n",
    "v = tv['speed']\n",
    "v = np.array([e for e in v if not np.isnan(e)])\n",
    "\n",
    "vx = tv['vx']\n",
    "vx = np.array([e for e in vx if not np.isnan(e)])\n",
    "\n",
    "vy = tv['vy']\n",
    "vy = np.array([e for e in vy if not np.isnan(e)])\n",
    "\n",
    "counts_vx, bins = np.histogram(vx, bins=np.linspace(-5, 5, 200), density=True) # normalised\n",
    "counts_vy, bins2 = np.histogram(vy, bins=np.linspace(-5, 5, 200), density=True) # normalised\n",
    "plt.stairs(counts_vx, bins, label=\"$v_x$\")\n",
    "plt.xlabel(\"$v_x$\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(\"Velocity distribution\")\n",
    "#plt.savefig(\"figs/funky_distribution.png\")\n",
    "\n",
    "plt.stairs(counts_vy, bins2, label=\"$v_y$\")\n",
    "plt.xlabel(\"$v_y$\")\n",
    "plt.ylabel(\"Probability\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig(\"figs/funky_distribution.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9084a375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
